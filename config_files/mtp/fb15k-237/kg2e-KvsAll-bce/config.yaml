# fb15k-237-kg2e-KvsAll-bce
job.type: search
search.type: ax
dataset.name: fb15k-237

# training settings (fixed)
train:
  max_epochs: 100
  auto_correct: True

# this is faster for smaller datasets, but does not work for some models (e.g.,
# TransE due to a pytorch issue) or for larger datasets. Change to spo in such
# cases (either here or in ax section of model config), results will not be
# affected.
negative_sampling.implementation: sp_po

# validation/evaluation settings (fixed)
valid:
  every: 5
  metric: mean_reciprocal_rank_filtered_with_test
  filter_with_test: True
  early_stopping:
    patience: 10
    threshold.epochs: 50
    threshold.metric_value: 0.05

eval:
  batch_size: 256
  metrics_per.relation_type: True

# settings for reciprocal relations (if used)
import: [kg2e, reciprocal_relations_model]
reciprocal_relations_model.base_model.type: kg2e

# ax settings: hyperparameter serach space
ax_search:
  num_trials: 15
  num_sobol_trials: 15
  parameters:
    # model
    - name: model
      type: choice
      values: [kg2e, reciprocal_relations_model]

    # training hyperparameters
    - name: train.batch_size
      type: fixed
      value: 256
    - name: train.type
      type: fixed
      value: KvsAll
    - name: train.optimizer
      type: choice
      values: [ Adam, Adagrad ]
    - name: train.loss
      type: fixed
      value: bce
    - name: train.optimizer_args.lr
      type: range
      bounds: [ 0.0003, 1.0 ]
      log_scale: True
    - name: train.lr_scheduler
      type: fixed
      value: ReduceLROnPlateau
    - name: train.lr_scheduler_args.mode
      type: fixed
      value: max
    - name: train.lr_scheduler_args.factor
      type: fixed
      value: 0.95
    - name: train.lr_scheduler_args.threshold
      type: fixed
      value: 0.0001
    - name: train.lr_scheduler_args.patience
      type: range
      bounds: [ 0, 10 ]

    # embedding dimension
    - name: lookup_embedder.dim
      type: choice
      values: [ 128, 256, 512 ]
      is_ordered: True

    # embedding initialization
    - name: lookup_embedder.initialize
      type: choice
      values: [ xavier_normal_, xavier_uniform_, normal_, uniform_ ]
    - name: lookup_embedder.initialize_args.normal_.mean
      type: fixed
      value: 0.0
    - name: lookup_embedder.initialize_args.normal_.std
      type: range
      bounds: [ 0.00001, 1.0 ]
      log_scale: True
    - name: lookup_embedder.initialize_args.uniform_.a
      type: range
      bounds: [ -1.0, -0.00001 ]
    - name: lookup_embedder.initialize_args.xavier_uniform_.gain
      type: fixed
      value: 1.0
    - name: lookup_embedder.initialize_args.xavier_normal_.gain
      type: fixed
      value: 1.0

    # embedding regularization
    - name: lookup_embedder.regularize
      type: choice
      values: [ '', 'l3', 'l2', 'l1' ]
      is_ordered: True
    - name: lookup_embedder.regularize_args.weighted
      type: choice
      values: [ True, False ]
    - name: kg2e.entity_embedder.regularize_weight
      type: range
      bounds: [ 1.0e-20, 1.0e-01 ]
      log_scale: True
    - name: kg2e.relation_embedder.regularize_weight
      type: range
      bounds: [ 1.0e-20, 1.0e-01 ]
      log_scale: True

    # embedding dropout
    - name: kg2e.entity_embedder.dropout
      type: range
      bounds: [ -0.5, 0.5 ]
    - name: kg2e.relation_embedder.dropout
      type: range
      bounds: [ -0.5, 0.5 ]

    # training-type specific hyperparameters
    - name: KvsAll.label_smoothing            #train_type: KvsAll
      type: range                             #train_type: KvsAll
      bounds: [ -0.3, 0.3 ]                     #train_type: KvsAll
    # model-specific entries
